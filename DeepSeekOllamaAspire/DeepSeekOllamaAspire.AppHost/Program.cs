var builder = DistributedApplication.CreateBuilder(args);

// ğŸ‘‡ğŸ¼ Configure Ollama server hosting integration
var ollama =
    builder.AddOllama("ollama") // ğŸ‘ˆğŸ¼ Add Ollama container to the app host
        .WithDataVolume() // ğŸ‘ˆğŸ¼ Adds a data volume to store models
        .WithGPUSupport() // ğŸ‘ˆğŸ¼ Use your beefy GPU ğŸ‰
        .WithLifetime(ContainerLifetime.Persistent); // ğŸ‘ˆğŸ¼ Keep the container running when the app exits

// ğŸ‘‡ğŸ¼ Add DeepSeek-R1 model to Ollama server
var chat =
    ollama.AddModel("chat", "deepseek-r1:1.5b");

var apiService = 
    builder.AddProject<Projects.DeepSeekOllamaAspire_ApiService>("apiservice")
           // ğŸ‘‡ğŸ¼ Our Web API relies on Ollama chat and waits for it to start 
           .WithReference(chat)
           .WaitFor(chat);

builder.AddProject<Projects.DeepSeekOllamaAspire_Web>("webfrontend")
    .WithExternalHttpEndpoints()
    .WithReference(apiService)
    .WaitFor(apiService);

builder.Build().Run();
